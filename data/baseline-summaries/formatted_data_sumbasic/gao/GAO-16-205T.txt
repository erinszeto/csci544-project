i am pleased to be here today to discuss the u.s. census bureau's ( bureau ) preparations to implement information technology ( it ) solutions for the 2020 census .

on october 6 , 2015 , the bureau released the first version of its 2020 census operational plan , which is intended to outline the design decisions that drive how the 2020 census will be conducted .

these design decisions are expected to significantly transform how the bureau conducts the decennial census , in an effort to save approximately $5.2 billion .

the redesign largely depends on implementing new technology and systems to modernize and automate many parts of the decennial census .

accordingly , concurrent with the overhaul of the 2020 census , the bureau is also significantly redesigning the it systems that support each of its surveys , including the decennial census .

with less than 2 years remaining for the bureau to put all systems and operations place to prepare for end - to - end testing , this hearing is timely .

my statement today will describe critical challenges the bureau faces in successfully delivering the needed it systems for the 2020 census .

the information in this testimony is based primarily on our previous reports on the bureau's planning efforts for the 2020 census .

more detail on our scope and methodology is provided in each published report cited in this testimony .

we also obtained and reviewed information on the bureau's actions in response to our previous recommendations .

the work on which this statement is based was conducted in accordance with generally accepted government auditing standards .

those standards require that we plan and perform the audit to obtain sufficient , appropriate evidence to provide a reasonable basis for our findings and conclusions based on our audit objectives .

we believe that the evidence obtained provides a reasonable basis for our findings and conclusions based on our audit objectives .

as you know , the cost of the decennial census has steadily increased during the past 40 years , in part because the nation's population has steadily grown larger , more diverse , and increasingly difficult to enumerate .

for example , at about $13 billion , the 2010 census was the costliest u.s. census in history and was 56 percent more costly than the $8.1 billion 2000 census ( in constant 2010 dollars ) .

to help save costs , in preparing for the 2020 census , the bureau has been researching and testing new methods and technologies to redesign the census to more cost - effectively count the population while maintaining high - quality results .

the bureau's research and testing has focused on four redesign areas: reengineering address canvassing: this involves reengineering processes for updating the bureau's address list and maps of the nation to reduce the need for employing field staff to walk every street in the nation to verify addresses .

optimizing self - response: includes efforts to maximize the self - response of households by , among other things , offering an internet response option .

as we have previously reported , to deliver the internet response option , the bureau would need to , among other things , design and develop an internet response application , develop and acquire the it infrastructure to support a large volume of data processing and storage , and plan communication and outreach strategies to motivate households to respond via the internet .

using administrative records: this includes expanding the use of data previously obtained by other federal and state government agencies and commercial sources to reduce the need for costly and labor - intensive follow - up work .

my colleague will address the bureau's progress on using administrative records in his statement today .

reengineering field operations: this includes reducing the number of visits to households , automating the management of enumerator work to conduct non - response follow - up , and automating and optimizing case assignment and routing for enumerators to reduce the staffing , infrastructure , and field offices required for the 2020 census .

the bureau has conducted several major field tests to examine the potential for each of these redesign areas: in mid - 2014 the bureau conducted the 2014 census test in the maryland and washington , d.c. , areas to test new methods for conducting self - response and non - response follow - up .

in early 2015 the bureau completed the address validation test , which was used to examine new methods for updating the bureau's address list .

in mid - 2015 the bureau conducted the 2015 census test in arizona to test , among other things , the use of a field operations management system to automate data collection operations and provide real - time data and the ability to reduce the non - response follow - up workload using data previously provided to the government , as well as enabling enumerators to use their personally owned mobile devices to collect census data .

also in mid - 2015 , the bureau conducted an optimizing self - response test in savannah , georgia , and the surrounding area , which was intended to further explore methods of encouraging households to respond using the internet , such as using advertising and outreach to motivate respondents , and enabling households to respond without a bureau - issued identification number .

more recently , the bureau began its national content test , which is currently ongoing and intended to , among other things , continue to test self - response modes and contact strategies and refine estimates of national self - response and internet response rates .

these tests were intended to inform the first version of the bureau's 2020 census operational plan , which is intended to outline design decisions that drive how the 2020 census will be conducted .

as part of these decisions , the bureau has committed to aspects of the 2020 census redesign .

the operational plan articulated 326 total design decision points , which vary widely in their complexity , importance , and urgency .

as of october 6 , 2015 , the bureau had made decisions for about 47 percent of them related to each of the four redesign areas .

for example , the bureau has decided to conduct 100 percent of address canvassing ( i.e. , identifying all addresses where people could live ) in the office , and target a subset of up to 25 percent for in - the - field address canvassing ; offer an internet self - response option , as well as alternative response options via telephone and paper for limited circumstances ; allow people to respond without a unique census identification use mobile devices for enumerators to conduct field data collection ; use administrative records to enumerate vacant units ; use enterprise solutions to support the 2020 census , when practicable ; and reduce the field footprint by half in comparison to the 2010 census ( eg , 6 regional census centers instead of 12 and up to 250 field offices instead of nearly 500 ) .

figure 1 provides an overview of the bureau's current plans and assumptions for the 2020 census , resulting from the october 2015 operational plan .

as a result of these decisions , the bureau estimates saving $5.2 billion .

specifically , the bureau estimated that repeating the design of the 2010 census for 2020 would cost approximately $17.8 billion ( in constant 2020 dollars ) , while successfully implementing the four redesign areas is expected to result in an overall 2020 census cost of $12.5 billion ( in constant 2020 dollars ) .

table 1 illustrates the estimated cost savings associated with each redesign area .

moving forward , the bureau plans to conduct additional research and testing and further refine the design through 2018 .

by august 2017 , the bureau plans to begin preparations for end - to - end testing , which is intended to test all systems and operations to ensure readiness for the 2020 census .

figure 2 shows the timeline for planned 2020 census research and testing .

concurrent with redesigning the decennial census , the bureau has also begun a significant effort to modernize and consolidate its survey data collection and processing functions .

this is being undertaken through an enterprise - wide it initiative called census enterprise data collection and processing ( cedcap ) .

this initiative is a large and complex modernization program intended to deliver a system - of - systems for all the bureau's survey data collection and processing functions — rather than continuing to rely on unique , survey - specific systems with redundant capabilities .

for the 2020 census , cedcap is expected to deliver the systems and it infrastructure needed to implement the bureau's redesign areas .

for example: to reengineer field work , cedcap is expected to implement a new dynamic operational control system to track and manage field work .

this system is to be able to make decisions about which visits enumerators should attempt on a daily basis using real - time data , as well as provide automated route planning to make enumerator travel more efficient .

cedcap also includes testing the use of mobile devices , either government - furnished or employee - owned , to automate data collection in the field .

to maximize self - response with the internet response option , cedcap is responsible for developing and testing a web - based survey application and exploring options for establishing the it infrastructure to support the increased volume of data processing and storage that will be needed .

cedcap consists of 12 projects that are to deliver capabilities incrementally , over the course of at least 10 releases .

the bureau plans to roll out capabilities for the 2020 census incrementally through 6 of these releases , while also deploying capabilities for other surveys such as the american community survey and economic census .

the bureau expects to reuse selected systems , make modifications to other systems , and develop or acquire additional systems and infrastructure .

as of august 2015 , the cedcap program was projected to cost about $548 million through 2020 .

however , the bureau's past efforts to implement new approaches and systems have not always gone well .

as one example , during the 2010 census , the bureau planned to use handheld mobile devices to support field data collection for the census , including following up with nonrespondents .

however , due to significant problems identified during testing of the devices , cost overruns , and schedule slippages , the bureau decided not to use the handheld devices for non - response follow - up and reverted to paper - based processing , which increased the cost of the 2010 census by up to $3 billion and significantly increased its risk as it had to switch its operations to paper - based operations as a backup .

last month's issuance of the 2020 census operational plan , which documents many key decisions about the redesign of the 2020 census , represents progress ; however , the bureau faces critical challenges in delivering the it systems needed to support the redesign areas .

specifically , with preparations for end - to - end testing less than 2 years away , the window to implement cedcap , which is intended to be the backbone of the 2020 census , is narrow .

additionally , while the bureau has demonstrated improvements in it management , as we have previously reported , it faces critical gaps in its it workforce planning and information security .

until it takes actions we have previously recommended to address these challenges , the bureau is at risk of cost overruns , schedule delays , and performance shortfalls , which will likely diminish the potentially significant cost savings that it estimates will result from redesigning the census for 2020 .

the bureau has not prioritized key it - related decisions , which is a trend we have reported for the past few years .

specifically , in april 2014 , we reported the bureau had not prioritized key it research and testing needed for the design decisions planned for the end of 2015 .

in particular , the bureau had not completed the necessary plans and schedules for research and testing efforts and had not prioritized what needed to be done in time for the 2015 design decisions — a milestone that had already been pushed back by a year ( see fig .

3 ) .

we concluded that , given the current trajectory and the lack of supporting schedules and plans , it was unlikely that all planned it - related research and testing activities would be completed in time to support the 2015 design decisions — which ultimately came to fruition ( as discussed later ) .

in light of these ongoing challenges , we recommended in our april 2014 report that the bureau prioritize its it - related research and testing projects that need to be completed to support the design decisions and develop schedules and plans to reflect the new prioritized approach .

the bureau agreed with our recommendations and has taken steps to address them .

for example , in september 2014 , the bureau released a plan that identified inputs , such as research questions , design components , and testing , that were needed to inform the operational design decisions expected in the fall of 2015 .

however , as we reported in february 2015 , the bureau had not yet determined how key it research questions that had been identified as critical inputs into the design decisions — estimating the internet self - response rate and determining the it infrastructure for security and scalability needed to support internet response — were to be answered .

we therefore recommended that the bureau , among other things , develop methodologies and plans for answering key it - related research questions in time to inform key design decisions .

while the recent 2020 census operational plan documents many key it - related decisions about the redesign of the census , other critical questions , including the ones identified in our february 2015 report , remain unanswered .

of greater concern , the bureau does not intend to answer these and other questions until 2016 through 2018 .

specifically , there are several significant it decisions that are being deferred , which have implications on the cedcap program's ability to have production - ready systems in place in time to conduct end - to - end testing .

for example , the bureau does not plan to decide on the projected demand that the it infrastructure and systems would need to accommodate or whether the bureau will build or buy the needed systems until june 2016 , at the earliest ; the high - level design and description of the systems ( referred to as the solutions architecture ) until september 2016 — leaving about a year to , among other things , build or acquire , integrate , and test the systems that are intended to serve as the backbone to the 2020 census before preparations for end - to - end testing begins in august 2017 ; and the strategy for the use of mobile devices for field work until october 2017 .

figure 4 illustrates several key it - related decisions that have been deferred which will impact preparations for the end - to - end test and 2020 census .

unless the bureau makes these key decisions soon , it will likely run out of time to put cedcap systems in place .

institutionalizing key it management controls , such as it governance , system development methodology , and requirements management processes , helps establish a consistent and repeatable process for managing and overseeing it investments and reduces the risk of experiencing cost overruns , schedule slippages , and performance shortfalls , like those that affected the previous census .

however , in september 2012 , we reported that the bureau lacked a sufficiently mature it governance process to ensure that investments are properly controlled and monitored , did not have a comprehensive system development methodology , and continued to have long - standing challenges in requirements management .

we made several recommendations to address these issues , and the bureau took actions to fully implement each of the recommendations .

for example , the bureau addressed gaps in policies and procedures related to it governance , such as establishing guidelines on the frequency of investment review board meetings and thresholds for escalation of cost , risk , or impact issues ; finalized its adoption of an enterprise system development life - cycle methodology , which included the short incremental development model , referred to as agile , and a process for continuously improving the methodology based on lessons learned ; and implemented a consistent requirements development tool that includes guidance for developing requirements at the strategic mission , business , and project levels and is integrated with its enterprise system development life - cycle methodology .

as a result , the bureau has established a consistent process for managing and overseeing its it investments .

effective workforce planning is essential to ensure organizations have the proper skills , abilities , and capacity for effective management .

while the bureau has made progress in it workforce planning efforts , many critical it competency gaps remain to be filled .

in september 2012 we reported , among other things , that the bureau had not developed a bureau - wide it workforce plan ; identified gaps in mission - critical it occupations , skills , and competencies ; or developed strategies to address gaps .

accordingly , we recommended that the bureau establish a repeatable process for performing it skills assessments and gap analyses and establish a process for directorates to coordinate on it workforce planning .

in response , in 2013 the bureau completed an enterprise - wide competency assessment and identified several mission - critical gaps in technical competencies .

in 2014 , the bureau established documents to institutionalize a strategic workforce planning process , identified actions and targets to close the competency gaps by december 2015 , and established a process to monitor quarterly status reports on the implementation of these actions .

however , as we reported in february 2015 , while these are positive steps in establishing strategic workforce planning capabilities , the bureau's workforce competency assessment identified several mission - critical gaps that would challenge its ability to deliver it - related initiatives , such as the it systems that are expected to be delivered by cedcap .

for example , the bureau found that competency gaps existed in cloud computing , security integration and engineering , enterprise / mission engineering life - cycle , requirements development , and internet data collection .

the bureau also found that enterprise - level competency gaps existed in program and project management , budget and cost estimation , systems development , data analytics , and shared services .

the bureau has taken steps to regularly monitor and report on the status of its efforts to close competency gaps and has completed several notable actions .

for example , in august 2015 , the bureau filled the position of decennial it division chief and in september 2015 awarded an enterprise - wide it services contract for systems engineering and integration support .

however , more work remains for the bureau to close competency gaps critical to the implementation of its it efforts .

most significantly , in july 2015 , the chief information officer resigned .

as of october 2015 , the bureau was working to fill that gap and had an acting chief information officer temporarily in the position .

additionally , there are other gaps in key positions , such as the chief of the office of information security and deputy chief information security officer , big data center chief , chief cloud architect , and the cedcap assistant chief of business integration , who is responsible for overseeing the integration of schedule , risks , and budget across the 12 projects .

according to bureau officials , they are working to address these gaps .

critical to the bureau's ability to perform its data collection and analysis duties are its information systems and the protection of the information they contain .

a data breach could result in the public's loss of confidence in the bureau , thus affecting its ability to collect census data .

to ensure the reliability of their computerized information , agencies should design and implement controls to prevent , limit , and detect unauthorized access to computing resources , programs , information , and facilities .

inadequate design or implementation of access controls increases the risk of unauthorized disclosure , modification , and destruction of sensitive information and disruption of service .

in january 2013 , we reported on the bureau's implementation of information security controls to protect the confidentiality , integrity , and availability of the information and systems that support its mission .

we concluded that the bureau had a number of weaknesses in controls intended to limit access to its systems and information , as well as those related to managing system configurations and unplanned events .

we attributed these weaknesses to the fact that the bureau had not fully implemented a comprehensive information security program , and made 115 recommendations aimed at addressing these deficiencies .

the bureau expressed broad agreement with the report and said it would work to find the best ways to address our recommendations .

as of october 29 , 2015 , the bureau had addressed 66 of the 115 recommendations we made in january 2013 .

of the remaining open recommendations , we have determined that 30 require additional actions by the bureau , and for the other 19 we have work under way to evaluate if they have been fully addressed .

the bureau's progress toward addressing our security recommendations is encouraging .

however , more work remains to address the recommendations .

a cyber incident recently occurred at the bureau , and while it appears to have had limited impact , it demonstrates vulnerabilities at the bureau .

specifically , in july 2015 , the bureau reported that it had been targeted by a cyber attack aimed at gaining access to its federal audit clearinghouse , which contains non - confidential information from state and local governments , nonprofit organizations , and indian tribes to facilitate oversight of federal grant awards .

according to bureau officials , the breach was limited to this database on a segmented portion of the bureau's network that does not touch administrative records or sensitive respondent data protected under title 13 of the u.s. code , and the hackers did not obtain the personally identifiable information of census and survey respondents .

given that the bureau is planning to build or acquire it systems to collect the public's personal information for the 2020 census in ways that it has not for previous censuses ( eg , web - based surveys , cloud computing , and enabling mobile devices to collect census data ) , continuing to implement our recommendations and apply it security best practices as it implements cedcap systems must be a high priority .

as a result of the bureau's challenges in key it internal controls and its looming deadline , we identified cedcap as an it investment in need of attention in our february 2015 high - risk report .

we recently initiated a review of the cedcap program for your subcommittees , and expect to issue a report in the spring of 2016 .

in conclusion , the bureau is pursuing initiatives to significantly reform its outdated and inefficient methods of conducting decennial censuses .

however , with less than 2 years remaining until the bureau plans to have all systems and processes for the 2020 census developed and ready for end - to - end testing , it faces challenges that pose significant risk to 2020 census program .

these include the magnitude of the planned changes to the design of the census , the bureau's prior track record in executing large - scale it projects , and the current lack of a permanent chief information officer , among others .

moreover , the bureau's preliminary decision deadline has come and gone , and many it - related decisions have been deferred to 2016 through 2018 .

consequently , it is running out of time to develop , acquire , and implement the production systems it will need to deliver the redesign and achieve its projected $5.2 billion in cost savings .

the bureau needs to take action to address the specific challenges we have highlighted in prior reports .

if these actions are not taken , cost overruns , schedules delays , and performance shortfalls may diminish the potentially significant cost savings that the bureau estimates will result from redesigning the census for 2020 .

chairmen meadows and hurd , ranking members connolly and kelly , and members of the subcommittees , this completes my prepared statement .

i would be pleased to respond to any questions that you may have .

if you have any questions concerning this statement , please contact carol cha , director , information technology acquisition management issues , at ( 202 ) 512-4456 or chac@gao.gov .

other individuals who made key contributions include shannin o'neill , assistant director ; andrew beggs ; lee mccracken ; and jeanne sung .

this is a work of the u.s. government and is not subject to copyright protection in the united states .

the published product may be reproduced and distributed in its entirety without further permission from gao .

however , because this work may contain copyrighted images or other material , permission from the copyright holder may be necessary if you wish to reproduce this material separately .

