assessing the achievement of students in elementary and secondary schools and the nation's educational progress is fundamental to informing education policy approaches .

congressional interest in this area includes and extends beyond the annual assessments administered by states to comply with the educational accountability requirements of title i - a of the elementary and secondary education act ( esea ) .

congressional interest in testing also encompasses a national assessment program , authorized by the national assessment of educational progress assessment act ( naepaa ; title iii , section 303 of p.l .

107-279 ) , and participation in international assessment programs , authorized by the education sciences reform act ( esra ; p.l .

107-279 , section 153 ( a ) ( 6 ) ) .

at the national level , students participate in the national assessment of educational progress ( naep ) .

at the international level , u.s. students participate in the trends in international mathematics and science study ( timss ) , progress in international reading literacy study ( pirls ) , and program for international student assessment ( pisa ) .

when national and international assessment results are released , there is a tendency to take the results of one assessment and present them as a snapshot of u.s. student achievement .

the focus on one set of assessment outcomes may result in a narrow and possibly misleading view of overall student achievement .

the primary purpose of this report is to provide background and context for the interpretation of national and international assessment scores so that results can be interpreted appropriately over time and across multiple assessments .

other purposes of this report are to describe specific national and international assessments , describe the recent results of these assessments , and clarify specific issues regarding the interpretation of assessment scores that explain the achievement of u.s. students .

national and international assessments are large - scale assessments of educational progress .

while some may also consider statewide assessments "large - scale," for the purposes of this report "large - scale assessments" refers only to national and international assessments .

these assessments differ from statewide and other assessments in several important ways .

first , large - scale assessments have different purposes than smaller - scale assessments .

second , there are different participation requirements and sampling procedures .

and , third , there are differences in the ways scores are typically reported for large - scale assessments versus smaller - scale assessments .

this section of the report discusses some of the major differences between large - scale and other , smaller - scale assessments , such as state and local assessments .

large - scale assessments are standardized assessments that are administered nationwide or worldwide .

u.s. students currently participate in two types of large - scale assessments: national assessments and international assessments .

the united states administers a series of national assessments called the national assessment of educational progress .

although naep is described as a single assessment , it is actually a series of two assessment programs: the main naep and the long - term trends ( ltt ) naep .

the main naep program consists of three subprograms: national naep , state naep , and the trial urban district assessment ( tuda ) .

the united states also participates in three major international assessments: the trends in international mathematics and science study ( timss ) , the progress in international reading literacy study ( pirls ) , and the program for international student assessment ( pisa ) .

table 1 provides a quick reference guide to the characteristics of the large - scale assessments discussed in this report .

appendix a provides additional information on large - scale assessments , such as authorization and oversight provisions .

the naep is referred to as the "nation's report card" because it is the only nationally representative assessment of what america's students know and can do in various content areas .

the original naep program began in 1969 and the first assessment was administered in 1971 .

the national assessment of educational progress authorization act authorizes the naep .

the commissioner for the national center for education statistics ( nces ) in the u.s. department of education ( ed ) is responsible for the administration of the naep .

the secretary of education appoints members to the national assessment governing board ( nagb ) to set the policy for naep administration .

the commissioner of nces and nagb meet regularly to coordinate activities .

in the first two decades of naep administration , there was no "main naep" program or "ltt naep" program .

beginning in 1990 , however , the naep program evolved into two separate assessment programs .

results of national and international assessments are difficult to interpret for a number of reasons .

perhaps the most difficult issue in the interpretation of large - scale assessments is processing the large volume of data presented in reports .

the results provided in the previous section are a small fraction of what is available .

these specific results were reported to provide a broad overview of the achievement of u.s. students across a wide range of assessments over time .

when large numbers of results are reported in national and international assessments , it can be challenging to compile assessment results across assessments to determine how well u.s. students are achieving over time and relative to other countries .

the purpose of this section of the report is to present a few issues to consider when interpreting national and international assessments .

this discussion is not intended to provide a comprehensive list of possible considerations ; however , the key issues presented below are pervasive across large - scale assessments .

since u.s. students participate in national assessments and several international assessments , there is a natural inclination to want to compare results from one assessment to another , especially when results are released within a short timeframe .

the most frequently administered assessments for u.s. students are annual statewide assessments and biennial naep assessments .

it often appears as if there is overlap in the content , timing , and grade - levels assessed , so it begs the question: can naep be compared to the results of statewide assessment systems required by the esea ? .

although u.s. students participate in international assessments less frequently , there is also apparent overlap in the content , timing , and grade - levels assessed .

this leads to questions such as , can naep be compared to international assessments ? .

if naep and timss both measure 8 th grade mathematics , are those results comparable ? .

if naep and pirls both measure 4 th grade reading , are those results comparable ? .

the answers to these questions largely depend on the alignment between assessments and the purpose of the comparison .

the following section of the report discusses some of the alignment studies that have been conducted and the usefulness of making comparisons across large - scale assessments .

as previously discussed , students already participate in myriad assessments at the state and local levels , including state assessments in reading , mathematics , and science required under esea title i - a .

these state assessments must be aligned with state standards in the relevant subject areas .

from a policy perspective , this raises obvious questions about why the united states participates in naep and international large - scale assessments when data on student performance are available from a multitude of other assessments .

while there are several reasons that the united states chooses to administer naep and to participate in international large - scale assessments , there are several factors that limit the use of national and international assessment results in shaping education policy .

in addition , it is unclear whether student achievement on international assessments may be related to economic prosperity and whether increasing student achievement on these assessments may be linked to improvements in a country's economic health .

when national and international assessment results are released , they provide a snapshot of the general condition of education .

tracking results over time can indicate whether students are making educational progress in certain content areas at certain grades .

if u.s. students are ranked significantly lower than many other countries and not making clear progress over time , it may signal a problem in elementary and secondary education policies and practices .

the results , however , may not be particularly helpful in identifying policies that may increase student achievement or aid the united states in meeting other educational goals , such as increasing high school graduation rates .

for example , u.s. students' achievement has significantly decreased over the last two administrations of pisa .

a decrease in achievement could represent an actual decrease in student achievement .

on the other hand , a decrease in achievement could be indicative of curricula that are misaligned with the test , teaching and learning practices in the u.s. that are different than what pisa requires , or even a lack of student engagement in the testing process .

with the numerous possibilities to explain student achievement , it may be unclear how policymakers should begin to address a decrease in achievement .

one way policymakers may consider addressing a decrease in achievement is to adopt policies and practices from countries that consistently score well on international assessments .

this approach raises myriad questions .

for example , is it in the best interest of the united states and its students to adopt the educational policies of countries that may be quite different than the united states ? .

other countries may differ from the united states in many ways , including with respect to their student populations , levels and distribution of education funding , policies regarding the tracking of students by academic ability , secondary school and university enrollment rates , and the quality of educator provided to subgroups of students ( eg , low - income students , english learners , students with disabilities , minority students ) .

and if it is determined that adopting the policies of another country is the best course of action , the feasibility of adopting such policies must be addressed , including whether educational policies are generalizable across countries and whether the will and capacity to make needed changes exists .

in addition , just as academic achievement in the united states has changed over time , the same is true for other countries .

for example , earlier in the 21 st century , finland was a top performer on pisa and viewed as a country having policies worthy of emulation .

however , in both the 2012 and 2015 administrations of the pisa , finland has seen its performance in science , math , and reading decline .

this raises questions about what would have happened if the united states had focused on mirroring finland's policies in the hopes of achieving finland's top level of performance .

the example of finland above highlights an important characteristic of international assessments â€“ these assessments provide a snapshot of achievement , but they do not evaluate policies and practices within or across countries .

the pisa did not evaluate the effectiveness of any policies or practices in place in finland .

the decline in achievement seen in finland in the 2012 and 2015 pisa assessments may have been due to a specific policy or practice or it may have been due to factors outside of education ( eg , economic health , political climate , changing demographics , etc. ) .

in the 1990s and early 2000s , pisa was not able to provide information on why students in finland were high achieving , and currently , pisa is not able to provide information on why the achievement of students in finland has declined .

none of the international assessments provides data on the factors that may explain student achievement .

even if it is possible to identify an education policy that would increase u.s. student achievement on national and international assessments , there may be barriers to implementing that policy .

compared to many other countries that participate in international assessments , the united states has a decentralized education system that primarily reserves the power to make education policy decisions for state and local authorities .

state and local authorities already rely upon state and local assessments to evaluate students , schools , and districts .

while the results of national and international assessments may , in some cases , highlight a problem , the assessment results may not offer a policy solution for states .

by contrast , state and local assessments are aligned with state content and performance standards , which possibly make them better suited than national and international assessments to address any perceived problems in teaching and learning at the state level .

for example , if student performance is trending downward in reading on a statewide assessment , state and local authorities may choose new curricula , allocate more teaching time to reading , or provide funding for reading specialists .

if student performance is trending downward in reading on an international assessment , state and local authorities cannot determine whether the score is low because student achievement is actually declining or if the test is not aligned with their content standards , curricula , or teaching practices .

there is considerable debate about the impact of student achievement on a country's economic prosperity .

several analyses have tried to link performance on international assessments to various indicators of national wealth and prosperity .

one analysis of the relationship between international test scores and "national success" that garnered attention was presented in 2007 by keith baker , a former researcher at ed .

baker used scores from 11 countries that participated in the first international mathematics study ( fims ) in 1964 to predict seven indicators of national success 30 years later: wealth , rate of growth , productivity , quality of life , livability , democracy , and creativity .

for almost all indicators , there was no relationship or a negative relationship between scores on fims and national success .

that is , as scores on international assessments increased , the wealth , rate of growth , etc .

of a nation decreased or remained the same .

increases in achievement , therefore , were associated with decreases in indicators of national success .

the one exception was the indicator of creativity ( as measured by the number of patents issued ) .

as international test scores increased , the creativity indicator also increased .

baker also analyzed the relationship between pisa and national success indicators .

results showed that nations at the pisa average generally outperformed other nations scoring well above or well below average .

based on these findings , baker concluded that there may be some baseline level of achievement that is important for national success ; however , once that baseline has been reached , focusing on increasing test scores may divert time and resources away from other factors that may contribute to national success .

another analysis that garnered attention was conducted by eric hanushek and ludgar woessmann and published by the oecd .

their analysis used economic modeling to predict the impact of achievement on international assessments on economic growth .

the model used growth in pisa scores over time to project growth in gross domestic product ( gdp ) in selected countries .

the results indicate that if all oecd countries increased their average pisa scores by 25 points over the next 20 years , the aggregate gain of oecd gdp over 80 years would be approximately $115 trillion .

furthermore , if all countries performed at a level of minimal proficiency for the oecd , the aggregate gdp would increase $200 trillion .

without a clearer picture of how performance on international assessments contributes to a country's economic prosperity , it may be difficult to decide whether attempting to increase international test scores for this purpose would be a worthwhile education policy goal .

given limited time and resources , policymakers may choose to focus efforts on other factors that contribute to educational achievement and economic prosperity .

given the overwhelming amount of data gathered by national and international assessments , it is difficult to comb through all of the results and gain a clear picture of the achievement of u.s. students over time and relative to other countries .

perhaps even more difficult is understanding the policies and practices that drive performance on these assessments .

for example , in the last decade , two secretaries of education have expressed concern over u.s. performance on the pisa and called for different reforms to address the problem .

in 2010 , secretary arne duncan used u.s. performance on the pisa to argue for advancing the education policy goals of the obama administration , most notably changes to teacher recruitment , teacher evaluation , and the compensation of highly effective teachers .

he argued that the oecd found that most high - achieving countries in pisa have policies that mirror the obama administration's focus on highly effective teachers .

by contrast , secretary betsy devos used u.s. performance on pisa to argue for advancing the education policy goals of the trump administration , most notably school choice .

she argued that countries that outperform the united states on pisa have more quickly adopted school choice policies .

clearly , education leaders have been concerned about the performance of u.s. students on international assessments ; however , the data from the assessments do not point to either a conclusive policy problem or solution .

both naep and international large - scale assessments provide the united states with comparative data about student achievement that is not available through assessments administered only at the state and local level .

having these data to examine student performance at a given moment in time and over the long term can be used in many ways , including as a check to confirm or contradict what data from state and local assessments indicate about student performance .

while naep is developed and implemented solely in the united states , the results of the assessments may have limited value in identifying particular policies or practices that are and are not working for u.s. students .

since naep is not aligned with any particular state's standards or curricula , it cannot provide direct feedback on how well students within a state are achieving the state's standards .

although , naep results do provide states with an opportunity to benchmark themselves against other states that operate in the same decentralized system of educational control .

international large - scale assessments also offer benchmarking and like naep may be less useful with respect to determining which policies and practices are contributing to student success and whether those policies and practices could be successfully implemented in locales within the united states .

thus , while national and international assessments may provide valuable data , the data do not easily translate into effective education policies .

the results , therefore , may be more useful in identifying areas in need of attention or resources and may have limited utility for shaping education policy approaches .

appendix a .

national and international educational assessments: authorization and oversight provisions appendix b .

additional resources on national and international assessments for more information on naep: https: / / nces.ed.gov / nationsreportcard / for more information on timss: https: / / nces.ed.gov / timss / https: / / iea.nl / timss / for more information on pirls: https: / / nces.ed.gov / surveys / pirls / https: / / iea.nl / pirls / for more information on pisa: https: / / nces.ed.gov / surveys / pisa / http: / / www.oecd.org / pisa / for more information on the coordination of naep and international assessments: https: / / nces.ed.gov / nationsreportcard / about / international.aspx other crs reports on assessment in elementary and secondary education: crs in focus if11021 , national and international educational assessments crs report r45048 , basic concepts and technical considerations in educational assessment: a primer crs report r45049 , educational assessment and the elementary and secondary education act appendix c. glossary of acronyms ccss: common core state standards ed: u.s. department of education el: english learner esea: elementary and secondary education act esra: education sciences reform act ( p.l .

107-279 , title i ) essa: every student succeeds act ( p.l .

114-95 ) fims: first international math study gdp: gross domestic product iea: international association for the evaluation of educational achievement ltt naep: long - term trends national assessment of educational progress naep: national assessment of educational progress naepaa: national assessment of educational progress assessment act ( p.l .

107-279 , title iii ) nagb: national assessment governing board nces: national center for education statistics nclb: no child left behind act ( p.l .

107-110 ) nslp: national school lunch program oecd: organisation for economic cooperation and development parcc: partnership for assessment of readiness for college and careers pirls: progress in international reading literacy study pisa: program for international student assessment sbac: smarter balanced assessment consortium tuda: trial urban district assessment ( part of naep ) timss: trends in international mathematics and science stud .

